{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pyreadr\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "# check pytorch version\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our training dataset.\n",
    "pred_vars = pyreadr.read_r(\"/home/germanm2/n_policy_box/Data/files_rds/pred_vars.rds\")[None] # also works for RData\n",
    "pred_vars = [item for sublist in pred_vars.values.tolist()  for item in sublist]\n",
    "\n",
    "TrainSet_eonr2_df = pyreadr.read_r(\"/home/germanm2/n_policy_box/Data/files_rds/TrainSet_eonr2.rds\")[None] # also works for RData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class to get our dataset.\n",
    "class Data(Dataset):\n",
    "    def __init__(self, TrainSet_eonr2_df):\n",
    "        self.x=torch.FloatTensor(TrainSet_eonr2_df[pred_vars].values)\n",
    "        self.y=torch.FloatTensor(TrainSet_eonr2_df['eonr'].values)\n",
    "        self.y=self.y.view(-1,1)\n",
    "        self.len=self.x.shape[0]\n",
    "    def __getitem__(self,index):         \n",
    "        return self.x[index],self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=Data(TrainSet_eonr2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class for creating our model.\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, cols):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(cols, 21)   # hidden layer\n",
    "        self.hidden2 = torch.nn.Linear(21, 10)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(10, 1)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))      # activation function for hidden layer\n",
    "        x = F.relu(self.hidden2(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "    \n",
    "cols = len(pred_vars)\n",
    "model = Net(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Create the function to train our model, which accumulate lost for each iteration to obtain the cost.\n",
    "# def train(data_set,model,criterion, train_loader, optimizer, epochs=5):\n",
    "#     cost=[]    \n",
    "#     for epoch in range(epochs):\n",
    "#          #all the samples are used for training because they fit in memory\n",
    "#         total=0\n",
    "        \n",
    "#         for x,y in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             yhat=model(x)\n",
    "#             loss=criterion(yhat,y)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total+=loss.item()\n",
    "#         cost.append(total)\n",
    "#     plt.figure()\n",
    "#     plt.plot(cost)\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.ylabel('cost')\n",
    "#     plt.show()\n",
    "#     return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_set,model,criterion, optimizer, epochs=5):\n",
    "    cost=[]    \n",
    "    for epoch in range(epochs):\n",
    "         #all the samples are used for training because they fit in memory\n",
    "        total=0\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(data_set.x)\n",
    "        loss=criterion(yhat,data_set.y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total+=loss.item()\n",
    "        cost.append(total)\n",
    "    plt.figure()\n",
    "    plt.plot(cost)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('cost')\n",
    "    plt.show()\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a single item from enumerate\n",
    "\n",
    "# singleitem = next(iter(train_loader))\n",
    "# x = singleitem[0]\n",
    "# y = singleitem[1]\n",
    "# yhat = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(yhat,y)\n",
    "# criterion(yhat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create our model \n",
    "\n",
    "torch.manual_seed(0)\n",
    "learning_rate = 0.01\n",
    "criterion = torch.nn.MSELoss(size_average=False)  # this is for regression mean squared loss\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#train_loader=DataLoader(dataset=data_set,batch_size=5)\n",
    "COST=train(data_set,model,criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions with returned model\n",
    "prediction_set_aggregated_df = pyreadr.read_r(\"/home/germanm2/n_policy_box/Data/files_rds/prediction_set_aggregated_dt.rds\")[None] # also works for RData\n",
    "\n",
    "X = Variable(torch.FloatTensor(prediction_set_aggregated_df[pred_vars].values)) \n",
    "\n",
    "y_pred = model(X) #This outputs the value for regression\n",
    "y_pred=y_pred.data[:,0].numpy()\n",
    "\n",
    "prediction_set_aggregated_df['eonr_pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(prediction_set_aggregated_df['eonr_pred'].min(),\n",
    "prediction_set_aggregated_df['eonr_pred'].max(),\n",
    "prediction_set_aggregated_df['eonr_pred'].mean(),\n",
    "mean_squared_error(prediction_set_aggregated_df['eonr_12'], prediction_set_aggregated_df['eonr_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4050 3593 (21, 21, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(TrainSet_eonr2_df, policy, pred_vars):\n",
    "    #Define training hyperprameters.\n",
    "    batch_size = 50\n",
    "    num_epochs = 100\n",
    "    learning_rate = 0.01\n",
    "    size_hidden= 100\n",
    "    \n",
    "    y_train = TrainSet_eonr2_df['eonr']\n",
    "    #X_train = TrainSet_eonr2_df.drop('eonr', axis=1)\n",
    "    X_train = TrainSet_eonr2_df[pred_vars]\n",
    "    \n",
    "    X_train=X_train.values\n",
    "    y_train=y_train.values\n",
    "\n",
    "    #Calculate some other hyperparameters based on data.  \n",
    "    batch_no = len(X_train) // batch_size  #batches\n",
    "    cols=X_train.shape[1] #Number of columns in input matrix\n",
    "    n_output=1\n",
    "\n",
    "    #Create the model\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "    print(\"Executing the model on :\",device)\n",
    "\n",
    "    net = Net(cols, size_hidden, n_output)\n",
    "\n",
    "    #Adam is a specific flavor of gradient decent which is typically better\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    #optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "    criterion = torch.nn.MSELoss(size_average=False)  # this is for regression mean squared loss\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        #Shuffle just mixes up the dataset between epocs\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        # Mini batch learning\n",
    "        for i in range(batch_no):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            inputs = Variable(torch.FloatTensor(X_train[start:end]))\n",
    "            labels = Variable(torch.FloatTensor(y_train[start:end]))\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            #print(\"outputs\",outputs)\n",
    "            #print(\"outputs\",outputs,outputs.shape,\"labels\",labels, labels.shape)\n",
    "            loss = criterion(outputs, torch.unsqueeze(labels,dim=1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        #print('Epoch {}'.format(epoch+1), \"loss: \",running_loss)\n",
    "        running_loss = 0.0\n",
    "    path = '/home/germanm2/n_policy_box/Data/files_rds/cnn_models/'+ policy + '.pth'\n",
    "    torch.save(net.state_dict(), path)\n",
    "    return(net)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions with returned model\n",
    "prediction_set_aggregated_df = pyreadr.read_r(\"/home/germanm2/n_policy_box/Data/files_rds/prediction_set_aggregated_dt.rds\")[None] # also works for RData\n",
    "\n",
    "X_pred = prediction_set_aggregated_df[pred_vars]\n",
    "\n",
    "X_pred=X_pred.values\n",
    "\n",
    "X = Variable(torch.FloatTensor(X_pred)) \n",
    "y_pred = net_return(X) #This outputs the value for regression\n",
    "y_pred=y_pred.data[:,0].numpy()\n",
    "y_pred\n",
    "prediction_set_aggregated_df['eonr_pred'] = y_pred\n",
    "\n",
    "# now let's write a Rds\n",
    "pyreadr.write_rds(\"/home/germanm2/n_policy_box/Data/files_rds/prediction_set_aggregated_cnn_dt.rds\", prediction_set_aggregated_df)\n",
    "prediction_set_aggregated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the saved model\n",
    "policy = 'ratio_5'\n",
    "path = '/home/germanm2/n_policy_box/Data/files_rds/cnn_models/'+ policy + '.pth'\n",
    "net_load = Net(21, 100, 1)\n",
    "net_load.load_state_dict(torch.load(path))\n",
    "net_load.eval()\n",
    "net_load.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions with the saved model\n",
    "prediction_set_aggregated_df = pyreadr.read_r(\"/home/germanm2/n_policy_box/Data/files_rds/prediction_set_aggregated_dt.rds\")[None] # also works for RData\n",
    "\n",
    "X_pred = prediction_set_aggregated_df[pred_vars]\n",
    "X_pred=X_pred.values\n",
    "X_pred\n",
    "X = Variable(torch.FloatTensor(X_pred)) \n",
    "y_pred = net_load(X) #This outputs the value for regression\n",
    "y_pred=y_pred.data[:,0].numpy()\n",
    "y_pred\n",
    "prediction_set_aggregated_df['eonr_pred'] = y_pred\n",
    "\n",
    "# now let's write a Rds\n",
    "pyreadr.write_rds(\"/home/germanm2/n_policy_box/Data/files_rds/prediction_set_aggregated_cnn_dt.rds\", prediction_set_aggregated_df)\n",
    "prediction_set_aggregated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function that loads the saved model and does predictions\n",
    "\n",
    "prediction_set_aggregated_df = pyreadr.read_r(\"/home/germanm2/n_policy_box/Data/files_rds/prediction_set_aggregated_dt.rds\")[None]\n",
    "prediction_set_aggregated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cnn(prediction_set_aggregated_df, policy, pred_vars):\n",
    "    #Load the saved model\n",
    "    #policy = 'ratio_5'\n",
    "    path = '/home/germanm2/n_policy_box/Data/files_rds/cnn_models/'+ policy + '.pth'\n",
    "    net_load = Net(21, 100, 1)\n",
    "    net_load.load_state_dict(torch.load(path))\n",
    "    net_load.eval()\n",
    "    net_load.state_dict()\n",
    "    X_pred = prediction_set_aggregated_df[pred_vars]\n",
    "    X_pred=X_pred.values\n",
    "    X_pred\n",
    "    X = Variable(torch.FloatTensor(X_pred)) \n",
    "    y_pred = net_load(X) #This outputs the value for regression\n",
    "    y_pred=y_pred.data[:,0].numpy()\n",
    "    y_pred\n",
    "    prediction_set_aggregated_df['eonr_pred'] = y_pred\n",
    "    return(prediction_set_aggregated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function\n",
    "prediction_set_aggregated_df2 = predict_cnn(prediction_set_aggregated_df, 'ratio_5', pred_vars)\n",
    "prediction_set_aggregated_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(prediction_set_aggregated_df['eonr_pred'].min(),\n",
    "prediction_set_aggregated_df['eonr_pred'].max(),\n",
    "prediction_set_aggregated_df['eonr_pred'].mean(),\n",
    "mean_squared_error(prediction_set_aggregated_df['eonr_12'], prediction_set_aggregated_df['eonr_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3088\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "\n",
    "x = prediction_set_aggregated_df['eonr_12']\n",
    "y = prediction_set_aggregated_df['eonr_pred']\n",
    "\n",
    "plt.scatter(x, y, c=\"g\", alpha=0.5, marker=r'$\\clubsuit$',\n",
    "            label=\"Luck\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GEOANN]",
   "language": "python",
   "name": "conda-env-GEOANN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
