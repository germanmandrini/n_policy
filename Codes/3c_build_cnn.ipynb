{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n",
    "# https://colab.research.google.com/github/rpi-techfundamentals/website_spring_2020/blob/master/content/notebooks/20-deep-learning1/06-regression-bh-pytorch.ipynb#scrollTo=xD9PhAU7hoqT\n",
    "#!pip install torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, cols, size_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(cols, size_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(size_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(21, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(TrainSet_eonr2_df, policy):\n",
    "    y_train = TrainSet_eonr2_df['eonr']\n",
    "    X_train = TrainSet_eonr2_df.drop('eonr', axis=1)\n",
    "    #Define training hyperprameters.\n",
    "    batch_size = 50\n",
    "    num_epochs = 200\n",
    "    learning_rate = 0.01\n",
    "    size_hidden= 100\n",
    "    \n",
    "    #Calculate some other hyperparameters based on data.  \n",
    "    batch_no = len(X_train) // batch_size  #batches\n",
    "    cols=X_train.shape[1] #Number of columns in input matrix\n",
    "    n_output=1\n",
    "    #Create the model\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "    print(\"Executing the model on :\",device)\n",
    "    \n",
    "    net = Net(cols, size_hidden, n_output)\n",
    "    #Adam is a specific flavor of gradient decent which is typically better\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    #optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "    criterion = torch.nn.MSELoss(size_average=False)  # this is for regression mean squared loss\n",
    "    X_train=X_train.values\n",
    "    y_train=y_train.values\n",
    "    running_loss = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        #Shuffle just mixes up the dataset between epocs\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        # Mini batch learning\n",
    "        for i in range(batch_no):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            inputs = Variable(torch.FloatTensor(X_train[start:end]))\n",
    "            labels = Variable(torch.FloatTensor(y_train[start:end]))\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            #print(\"outputs\",outputs)\n",
    "            #print(\"outputs\",outputs,outputs.shape,\"labels\",labels, labels.shape)\n",
    "            loss = criterion(outputs, torch.unsqueeze(labels,dim=1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        #print('Epoch {}'.format(epoch+1), \"loss: \",running_loss)\n",
    "        running_loss = 0.0\n",
    "        path = '/home/germanm2/n_policy_box/Data/files_rds/cnn_models/'+ policy + '.pth'\n",
    "        torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the model on : cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/GEOANN/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# Build one CNN\n",
    "TrainSet_eonr2_df = pyreadr.read_r(\"/home/germanm2/n_policy_box/Data/files_rds/TrainSet_eonr2.rds\")[None] # also works for RData\n",
    "policy = 'ratio_5'\n",
    "build_cnn(TrainSet_eonr2_df, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cnn(prediction_set_aggregated_dt, policy):\n",
    "    #Initialize the eonr model:\n",
    "    cols=21 #Number of columns in input matrix        \n",
    "    n_output=1        \n",
    "    size_hidden= 100  \n",
    "    \n",
    "    #Load the cnn model\n",
    "    path = '/home/germanm2/n_policy_box/Data/files_rds/cnn_models/'+ policy + '.pth'\n",
    "    # net = torch.load(path)\n",
    "    net.load_state_dict(torch.load(path))\n",
    "    net.eval()\n",
    "    \n",
    "    #Get X data ready\n",
    "    X_pred=prediction_set_aggregated_dt.values\n",
    "    X = Variable(torch.FloatTensor(X_pred)) \n",
    "  \n",
    "    #Make predictions\n",
    "    y_pred = net(X) #This outputs the value for regression\n",
    "\n",
    "    y_pred=y_pred.data[:,0].numpy()\n",
    "\n",
    "    prediction_set_aggregated_dt['eonr_pred'] = y_pred\n",
    "    return(prediction_set_aggregated_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = 'ratio_5'\n",
    "#Load data\n",
    "prediction_set_aggregated_dt = pyreadr.read_r(\"/home/germanm2/n_policy_box/Data/files_rds/prediction_set_aggregated_dt.rds\")[None] # also works for RData\n",
    "prediction_set_aggregated_dt = prediction_set_aggregated_dt[['rain_30', 'rain_60','rain_90', 't_max_30', 't_max_60', 't_max_90', 't_min_30', 't_min_60', 't_min_90', 'Y_prev',\n",
    "    'Y_corn_lt_avg', 'day_sow', 'day_v5', 'lai_v5', 'whc', 'oc_20cm_v5', 'sw_dep_v5', 'n_0_60cm_v5', 'surfaceom_wt_v5', 'sand_40cm', 'clay_40cm']]\n",
    "\n",
    "predict_cnn(prediction_set_aggregated_dt, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Initialize the maturity prediction model:\n",
    "        model = MaturityPrediction()\n",
    "        \n",
    "        for model_code, model_field in field_codes.items():\n",
    "            # Define the location of the saved weigths:\n",
    "            model_file_name = f'../data/{model_code}_{fold}_rnd_1_noaug.pth'\n",
    "\n",
    "            # Load model parameters:\n",
    "            model.load_state_dict(torch.load(model_file_name))\n",
    "\n",
    "            # Load the model into the GPU:\n",
    "            model = model.to(device)\n",
    "            model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net()\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = prediction_set_aggregated_df[['rain_30', 'rain_60','rain_90', 't_max_30', 't_max_60', 't_max_90', 't_min_30', 't_min_60', 't_min_90', 'Y_prev',\n",
    " 'Y_corn_lt_avg', 'day_sow', 'day_v5', 'lai_v5', 'whc', 'oc_20cm_v5', 'sw_dep_v5', 'n_0_60cm_v5', 'surfaceom_wt_v5', 'sand_40cm', 'clay_40cm']]\n",
    "X_pred=X_pred.values\n",
    "\n",
    "X = Variable(torch.FloatTensor(X_pred)) \n",
    "y_pred = net(X) #This outputs the value for regression\n",
    "y_pred=y_pred.data[:,0].numpy()\n",
    "\n",
    "prediction_set_aggregated_df['eonr_pred'] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "X = Variable(torch.FloatTensor(X_train)) \n",
    "result = net(X)\n",
    "# pred=result.data[:,0].numpy()\n",
    "# print(len(pred),len(y_train))\n",
    "# r2_score(pred,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = prediction_set_aggregated_df[['rain_30', 'rain_60','rain_90', 't_max_30', 't_max_60', 't_max_90', 't_min_30', 't_min_60', 't_min_90', 'Y_prev',\n",
    " 'Y_corn_lt_avg', 'day_sow', 'day_v5', 'lai_v5', 'whc', 'oc_20cm_v5', 'sw_dep_v5', 'n_0_60cm_v5', 'surfaceom_wt_v5', 'sand_40cm', 'clay_40cm']]\n",
    "X_pred=X_pred.values\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE PREDICTIONS\n",
    "X = Variable(torch.FloatTensor(X_pred)) \n",
    "y_pred = net(X) #This outputs the value for regression\n",
    "y_pred=y_pred.data[:,0].numpy()\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_set_aggregated_df['eonr_pred'] = y_pred\n",
    "prediction_set_aggregated_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's write a Rds\n",
    "pyreadr.write_rds(\"/home/germanm2/n_policy_box/Data/files_rds/prediction_set_aggregated_cnn_df.rds\", prediction_set_aggregated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GEOANN]",
   "language": "python",
   "name": "conda-env-GEOANN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
