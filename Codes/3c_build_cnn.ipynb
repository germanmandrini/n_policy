{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n",
    "# https://colab.research.google.com/github/rpi-techfundamentals/website_spring_2020/blob/master/content/notebooks/20-deep-learning1/06-regression-bh-pytorch.ipynb#scrollTo=xD9PhAU7hoqT\n",
    "#!pip install torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, cols, size_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(cols, size_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(size_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(TrainSet_eonr2_df, policy):\n",
    "    y_train = TrainSet_eonr2_df['eonr']\n",
    "    X_train = TrainSet_eonr2_df.drop('eonr', axis=1)\n",
    "    #Define training hyperprameters.\n",
    "    batch_size = 50\n",
    "    num_epochs = 200\n",
    "    learning_rate = 0.01\n",
    "    size_hidden= 100\n",
    "    \n",
    "    #Calculate some other hyperparameters based on data.  \n",
    "    batch_no = len(X_train) // batch_size  #batches\n",
    "    cols=X_train.shape[1] #Number of columns in input matrix\n",
    "    n_output=1\n",
    "    #Create the model\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "    print(\"Executing the model on :\",device)\n",
    "    \n",
    "    net = Net(cols, size_hidden, n_output)\n",
    "    #Adam is a specific flavor of gradient decent which is typically better\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    #optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "    criterion = torch.nn.MSELoss(size_average=False)  # this is for regression mean squared loss\n",
    "    X_train=X_train.values\n",
    "    y_train=y_train.values\n",
    "    running_loss = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        #Shuffle just mixes up the dataset between epocs\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        # Mini batch learning\n",
    "        for i in range(batch_no):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            inputs = Variable(torch.FloatTensor(X_train[start:end]))\n",
    "            labels = Variable(torch.FloatTensor(y_train[start:end]))\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            #print(\"outputs\",outputs)\n",
    "            #print(\"outputs\",outputs,outputs.shape,\"labels\",labels, labels.shape)\n",
    "            loss = criterion(outputs, torch.unsqueeze(labels,dim=1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        #print('Epoch {}'.format(epoch+1), \"loss: \",running_loss)\n",
    "        running_loss = 0.0\n",
    "        path = '/home/germanm2/n_policy_box/Data/files_rds/cnn_models/'+ policy + '.pth'\n",
    "        torch.save(net.state_dict(), path)\n",
    "        return(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the model on : cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/GEOANN/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hidden): Linear(in_features=21, out_features=100, bias=True)\n",
       "  (predict): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build one CNN\n",
    "TrainSet_eonr2_df = pyreadr.read_r(\"/home/germanm2/n_policy_box/Data/files_rds/TrainSet_eonr2.rds\")[None] # also works for RData\n",
    "policy = 'ratio_5'\n",
    "net_returned = build_cnn(TrainSet_eonr2_df, policy)\n",
    "net_returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cnn(prediction_set_aggregated_dt, policy, net):\n",
    "    #Initialize the eonr model:\n",
    "    cols=21 #Number of columns in input matrix        \n",
    "    n_output=1        \n",
    "    size_hidden= 100  \n",
    "    \n",
    "    #Load the cnn model\n",
    "    #path = '/home/germanm2/n_policy_box/Data/files_rds/cnn_models/'+ policy + '.pth'\n",
    "    # net = torch.load(path)\n",
    "    #net.load_state_dict(torch.load(path))\n",
    "    #net.eval()\n",
    "    \n",
    "    #Get X data ready\n",
    "    X_pred=prediction_set_aggregated_dt.values\n",
    "    X = Variable(torch.FloatTensor(X_pred)) \n",
    "  \n",
    "    #Make predictions\n",
    "    y_pred = net(X) #This outputs the value for regression\n",
    "\n",
    "    y_pred=y_pred.data[:,0].numpy()\n",
    "\n",
    "    prediction_set_aggregated_dt['eonr_pred'] = y_pred\n",
    "    return(prediction_set_aggregated_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = 'ratio_5'\n",
    "#Load data\n",
    "prediction_set_aggregated_dt = pyreadr.read_r(\"/home/germanm2/n_policy_box/Data/files_rds/prediction_set_aggregated_dt.rds\")[None] # also works for RData\n",
    "prediction_set_aggregated_dt = prediction_set_aggregated_dt[['rain_30', 'rain_60','rain_90', 't_max_30', 't_max_60', 't_max_90', 't_min_30', 't_min_60', 't_min_90', 'Y_prev',\n",
    "    'Y_corn_lt_avg', 'day_sow', 'day_v5', 'lai_v5', 'whc', 'oc_20cm_v5', 'sw_dep_v5', 'n_0_60cm_v5', 'surfaceom_wt_v5', 'sand_40cm', 'clay_40cm']]\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain_30</th>\n",
       "      <th>rain_60</th>\n",
       "      <th>rain_90</th>\n",
       "      <th>t_max_30</th>\n",
       "      <th>t_max_60</th>\n",
       "      <th>t_max_90</th>\n",
       "      <th>t_min_30</th>\n",
       "      <th>t_min_60</th>\n",
       "      <th>t_min_90</th>\n",
       "      <th>Y_prev</th>\n",
       "      <th>...</th>\n",
       "      <th>day_v5</th>\n",
       "      <th>lai_v5</th>\n",
       "      <th>whc</th>\n",
       "      <th>oc_20cm_v5</th>\n",
       "      <th>sw_dep_v5</th>\n",
       "      <th>n_0_60cm_v5</th>\n",
       "      <th>surfaceom_wt_v5</th>\n",
       "      <th>sand_40cm</th>\n",
       "      <th>clay_40cm</th>\n",
       "      <th>eonr_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.050000</td>\n",
       "      <td>15.216667</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>-4.633333</td>\n",
       "      <td>4573.630436</td>\n",
       "      <td>...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.408</td>\n",
       "      <td>294.075688</td>\n",
       "      <td>1.620588</td>\n",
       "      <td>629.483784</td>\n",
       "      <td>35.048204</td>\n",
       "      <td>465.378891</td>\n",
       "      <td>5.071375</td>\n",
       "      <td>21.024234</td>\n",
       "      <td>182.093628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.133333</td>\n",
       "      <td>15.933333</td>\n",
       "      <td>3.383333</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>-6.650000</td>\n",
       "      <td>4234.758929</td>\n",
       "      <td>...</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.402</td>\n",
       "      <td>294.075688</td>\n",
       "      <td>1.625338</td>\n",
       "      <td>666.127141</td>\n",
       "      <td>42.310082</td>\n",
       "      <td>511.010443</td>\n",
       "      <td>5.071375</td>\n",
       "      <td>21.024234</td>\n",
       "      <td>176.533569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>16.783333</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>7.883333</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>-2.416667</td>\n",
       "      <td>4464.527031</td>\n",
       "      <td>...</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.406</td>\n",
       "      <td>294.075688</td>\n",
       "      <td>1.622531</td>\n",
       "      <td>620.573678</td>\n",
       "      <td>46.126236</td>\n",
       "      <td>497.375201</td>\n",
       "      <td>5.071375</td>\n",
       "      <td>21.024234</td>\n",
       "      <td>178.231461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22.016667</td>\n",
       "      <td>17.066667</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>-2.333333</td>\n",
       "      <td>4179.852874</td>\n",
       "      <td>...</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.397</td>\n",
       "      <td>294.075688</td>\n",
       "      <td>1.620151</td>\n",
       "      <td>629.544435</td>\n",
       "      <td>70.271481</td>\n",
       "      <td>462.792524</td>\n",
       "      <td>5.071375</td>\n",
       "      <td>21.024234</td>\n",
       "      <td>174.403366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>23.916667</td>\n",
       "      <td>12.283333</td>\n",
       "      <td>8.650000</td>\n",
       "      <td>9.416667</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>-2.366667</td>\n",
       "      <td>4362.798253</td>\n",
       "      <td>...</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.398</td>\n",
       "      <td>294.075688</td>\n",
       "      <td>1.623718</td>\n",
       "      <td>623.843297</td>\n",
       "      <td>47.598318</td>\n",
       "      <td>721.119533</td>\n",
       "      <td>5.071375</td>\n",
       "      <td>21.024234</td>\n",
       "      <td>180.963776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60362</th>\n",
       "      <td>251.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>23.083333</td>\n",
       "      <td>15.950000</td>\n",
       "      <td>14.833333</td>\n",
       "      <td>11.316667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>3710.355172</td>\n",
       "      <td>...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.332</td>\n",
       "      <td>283.620092</td>\n",
       "      <td>1.141886</td>\n",
       "      <td>709.097091</td>\n",
       "      <td>42.566269</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>20.469739</td>\n",
       "      <td>19.590676</td>\n",
       "      <td>164.336716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60363</th>\n",
       "      <td>138.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>22.150000</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>10.900000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>3576.472499</td>\n",
       "      <td>...</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.314</td>\n",
       "      <td>283.620092</td>\n",
       "      <td>1.140929</td>\n",
       "      <td>654.037549</td>\n",
       "      <td>29.381942</td>\n",
       "      <td>143.842076</td>\n",
       "      <td>20.469739</td>\n",
       "      <td>19.590676</td>\n",
       "      <td>166.382339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60364</th>\n",
       "      <td>141.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>21.766667</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>7.133333</td>\n",
       "      <td>10.133333</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>-2.766667</td>\n",
       "      <td>4670.014531</td>\n",
       "      <td>...</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.289</td>\n",
       "      <td>283.620092</td>\n",
       "      <td>1.141471</td>\n",
       "      <td>664.828798</td>\n",
       "      <td>27.620442</td>\n",
       "      <td>211.432364</td>\n",
       "      <td>20.469739</td>\n",
       "      <td>19.590676</td>\n",
       "      <td>171.695358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60365</th>\n",
       "      <td>190.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>20.883333</td>\n",
       "      <td>9.366667</td>\n",
       "      <td>9.383333</td>\n",
       "      <td>5.316667</td>\n",
       "      <td>-2.350000</td>\n",
       "      <td>4638.185289</td>\n",
       "      <td>...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.320</td>\n",
       "      <td>283.620092</td>\n",
       "      <td>1.137555</td>\n",
       "      <td>670.810914</td>\n",
       "      <td>28.431346</td>\n",
       "      <td>94.554173</td>\n",
       "      <td>20.469739</td>\n",
       "      <td>19.590676</td>\n",
       "      <td>168.055328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60366</th>\n",
       "      <td>94.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>20.516667</td>\n",
       "      <td>17.933333</td>\n",
       "      <td>14.350000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>4.383333</td>\n",
       "      <td>2.716667</td>\n",
       "      <td>3289.575449</td>\n",
       "      <td>...</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.303</td>\n",
       "      <td>283.620092</td>\n",
       "      <td>1.141886</td>\n",
       "      <td>637.059668</td>\n",
       "      <td>31.267461</td>\n",
       "      <td>142.365077</td>\n",
       "      <td>20.469739</td>\n",
       "      <td>19.590676</td>\n",
       "      <td>169.160095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60367 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rain_30  rain_60  rain_90   t_max_30   t_max_60   t_max_90   t_min_30  \\\n",
       "0        125.0    229.0     17.0  22.050000  15.216667   8.250000   9.900000   \n",
       "1        140.0    108.0     19.0  22.133333  15.933333   3.383333  10.300000   \n",
       "2         96.0    101.0     39.0  20.666667  16.783333   9.250000   7.883333   \n",
       "3         96.0     47.0     33.0  22.016667  17.066667   9.600000   9.333333   \n",
       "4         43.0    183.0     51.0  23.916667  12.283333   8.650000   9.416667   \n",
       "...        ...      ...      ...        ...        ...        ...        ...   \n",
       "60362    251.0    117.0     53.0  23.083333  15.950000  14.833333  11.316667   \n",
       "60363    138.0     79.0    107.0  22.150000  17.666667  10.900000  11.200000   \n",
       "60364    141.0    124.0    120.0  21.766667  12.533333   7.133333  10.133333   \n",
       "60365    190.0     16.0    132.0  21.750000  20.883333   9.366667   9.383333   \n",
       "60366     94.0    143.0    214.0  20.516667  17.933333  14.350000   7.400000   \n",
       "\n",
       "       t_min_60  t_min_90       Y_prev  ...  day_v5  lai_v5         whc  \\\n",
       "0      3.533333 -4.633333  4573.630436  ...   152.0   0.408  294.075688   \n",
       "1      2.950000 -6.650000  4234.758929  ...   147.0   0.402  294.075688   \n",
       "2      3.533333 -2.416667  4464.527031  ...   157.0   0.406  294.075688   \n",
       "3      3.066667 -2.333333  4179.852874  ...   157.0   0.397  294.075688   \n",
       "4      1.466667 -2.366667  4362.798253  ...   147.0   0.398  294.075688   \n",
       "...         ...       ...          ...  ...     ...     ...         ...   \n",
       "60362  5.333333  2.866667  3710.355172  ...   123.0   0.332  283.620092   \n",
       "60363  5.500000 -0.166667  3576.472499  ...   125.0   0.314  283.620092   \n",
       "60364  2.866667 -2.766667  4670.014531  ...   129.0   0.289  283.620092   \n",
       "60365  5.316667 -2.350000  4638.185289  ...   128.0   0.320  283.620092   \n",
       "60366  4.383333  2.716667  3289.575449  ...   135.0   0.303  283.620092   \n",
       "\n",
       "       oc_20cm_v5   sw_dep_v5  n_0_60cm_v5  surfaceom_wt_v5  sand_40cm  \\\n",
       "0        1.620588  629.483784    35.048204       465.378891   5.071375   \n",
       "1        1.625338  666.127141    42.310082       511.010443   5.071375   \n",
       "2        1.622531  620.573678    46.126236       497.375201   5.071375   \n",
       "3        1.620151  629.544435    70.271481       462.792524   5.071375   \n",
       "4        1.623718  623.843297    47.598318       721.119533   5.071375   \n",
       "...           ...         ...          ...              ...        ...   \n",
       "60362    1.141886  709.097091    42.566269       207.000000  20.469739   \n",
       "60363    1.140929  654.037549    29.381942       143.842076  20.469739   \n",
       "60364    1.141471  664.828798    27.620442       211.432364  20.469739   \n",
       "60365    1.137555  670.810914    28.431346        94.554173  20.469739   \n",
       "60366    1.141886  637.059668    31.267461       142.365077  20.469739   \n",
       "\n",
       "       clay_40cm   eonr_pred  \n",
       "0      21.024234  182.093628  \n",
       "1      21.024234  176.533569  \n",
       "2      21.024234  178.231461  \n",
       "3      21.024234  174.403366  \n",
       "4      21.024234  180.963776  \n",
       "...          ...         ...  \n",
       "60362  19.590676  164.336716  \n",
       "60363  19.590676  166.382339  \n",
       "60364  19.590676  171.695358  \n",
       "60365  19.590676  168.055328  \n",
       "60366  19.590676  169.160095  \n",
       "\n",
       "[60367 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_cnn(prediction_set_aggregated_dt, policy, net_returned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[-0.0297, -0.1166,  0.1599,  ...,  0.0611,  0.0683, -0.1019],\n",
       "                      [ 0.0572,  0.0094, -0.0251,  ...,  0.1406, -0.0022, -0.1195],\n",
       "                      [-0.1941, -0.0422, -0.1658,  ...,  0.0566, -0.0864,  0.0334],\n",
       "                      ...,\n",
       "                      [-0.0111, -0.0164, -0.0520,  ...,  0.1685,  0.2119,  0.0752],\n",
       "                      [ 0.1124, -0.0167,  0.1739,  ...,  0.2027,  0.0721,  0.0609],\n",
       "                      [ 0.1063, -0.0288,  0.1322,  ..., -0.1265,  0.0336,  0.1667]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([-0.1202, -0.1990,  0.1582,  0.1973, -0.0834, -0.1861, -0.0431, -0.0993,\n",
       "                       0.0276,  0.1098,  0.0045,  0.1099,  0.1793,  0.2092,  0.2133, -0.0811,\n",
       "                       0.0279,  0.0737, -0.1619, -0.0896,  0.1100,  0.1916,  0.0935,  0.1362,\n",
       "                      -0.0465,  0.0536, -0.1766, -0.0758,  0.0827, -0.1536, -0.0397,  0.1075,\n",
       "                       0.1816,  0.1330,  0.1074, -0.2012,  0.1884,  0.1827,  0.1858, -0.1423,\n",
       "                      -0.0137, -0.0172, -0.1859,  0.1848, -0.0645,  0.1792, -0.1661,  0.1414,\n",
       "                       0.0119,  0.0571, -0.1317, -0.0795,  0.0977, -0.1796, -0.1407,  0.1124,\n",
       "                      -0.1457, -0.0342,  0.0738,  0.1719,  0.1838, -0.2123,  0.1882,  0.1151,\n",
       "                       0.0816,  0.1562,  0.1110, -0.0865, -0.0762, -0.0440,  0.0790, -0.1405,\n",
       "                      -0.0248,  0.0463, -0.0963, -0.0264, -0.1479,  0.1815,  0.1712,  0.0768,\n",
       "                      -0.1142, -0.1994, -0.1332,  0.0062, -0.0873, -0.1155,  0.0759, -0.1780,\n",
       "                       0.1862,  0.0716,  0.1209, -0.1176, -0.0734,  0.0839,  0.1777, -0.1258,\n",
       "                       0.1279, -0.1555,  0.1290, -0.1095])),\n",
       "             ('predict.weight',\n",
       "              tensor([[ 0.0098, -0.0236, -0.0367, -0.0860,  0.0595, -0.0431,  0.0075, -0.0133,\n",
       "                       -0.0413,  0.0372, -0.0969, -0.0990,  0.0663, -0.0899, -0.0045, -0.0558,\n",
       "                       -0.0489,  0.0326,  0.0390,  0.0370, -0.0238, -0.0818,  0.0023, -0.0297,\n",
       "                       -0.0487, -0.0717,  0.0137,  0.0966, -0.0074, -0.0751, -0.0489, -0.0306,\n",
       "                        0.0877,  0.0303, -0.0912,  0.0827, -0.0475,  0.0836,  0.0944,  0.0716,\n",
       "                        0.0478,  0.0462, -0.0398,  0.0362, -0.0468,  0.0539,  0.0226, -0.0688,\n",
       "                       -0.0209,  0.0594, -0.0778, -0.0544,  0.0627,  0.0498, -0.0922, -0.0515,\n",
       "                        0.0524, -0.0531, -0.0248,  0.0522, -0.0835, -0.0801, -0.0173,  0.0677,\n",
       "                        0.0981,  0.0623,  0.0795,  0.0337, -0.0352,  0.0148, -0.0668, -0.0464,\n",
       "                       -0.0794, -0.0422, -0.0514, -0.0399,  0.0248,  0.0195,  0.0714, -0.0167,\n",
       "                        0.0941,  0.0378,  0.0594,  0.0787,  0.0779, -0.0388,  0.0266, -0.0844,\n",
       "                       -0.0338,  0.0049, -0.0133, -0.0892, -0.0991,  0.0465, -0.0733, -0.0724,\n",
       "                       -0.0628,  0.0193, -0.0193,  0.0116]])),\n",
       "             ('predict.bias', tensor([-0.0372]))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = 'ratio_5'\n",
    "path = '/home/germanm2/n_policy_box/Data/files_rds/cnn_models/'+ policy + '.pth'\n",
    "net2 = Net(21, 100, 1)\n",
    "net2.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[-0.0676, -0.0373, -0.0625,  ..., -0.0039, -0.2168,  0.0727],\n",
       "                      [-0.1252, -0.0744, -0.0562,  ..., -0.1339, -0.1475,  0.1869],\n",
       "                      [ 0.1879, -0.0744, -0.0616,  ..., -0.1756,  0.0499, -0.2314],\n",
       "                      ...,\n",
       "                      [-0.1955,  0.1512, -0.1365,  ...,  0.0670, -0.1679,  0.0434],\n",
       "                      [ 0.1207,  0.0385,  0.1566,  ...,  0.0703,  0.0622,  0.0010],\n",
       "                      [ 0.1169,  0.1795, -0.0860,  ..., -0.1801, -0.1532, -0.1962]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([-0.0537,  0.1449, -0.1245,  0.0153,  0.0911, -0.1218, -0.0173,  0.0280,\n",
       "                       0.0580, -0.3124, -0.1526, -0.1387,  0.1176,  0.0327, -0.1876,  0.1053,\n",
       "                      -0.1954,  0.1189,  0.2141, -0.1075, -0.2272, -0.0854, -0.2294,  0.0227,\n",
       "                       0.0784,  0.0967,  0.0996, -0.0641, -0.1181,  0.0893,  0.1770, -0.0827,\n",
       "                      -0.2538, -0.1078,  0.0648, -0.0968, -0.1060, -0.1650, -0.0345, -0.0484,\n",
       "                       0.0710,  0.0583, -0.0253, -0.1054, -0.1782, -0.0317,  0.0053, -0.1927,\n",
       "                       0.1073, -0.1297, -0.1999,  0.1369,  0.1121, -0.2453,  0.1417,  0.0692,\n",
       "                       0.0474,  0.1481, -0.0113,  0.1698,  0.0015, -0.1651, -0.1385, -0.0097,\n",
       "                      -0.1946,  0.0901, -0.1554, -0.2093,  0.1432,  0.0078,  0.0937, -0.0760,\n",
       "                      -0.2003,  0.1421,  0.2173,  0.0411,  0.0294, -0.1756, -0.0482, -0.2211,\n",
       "                       0.1413,  0.1816, -0.1979, -0.1173,  0.1409, -0.1318, -0.0694, -0.0843,\n",
       "                      -0.1675,  0.1520,  0.1975, -0.1841,  0.0926,  0.0575,  0.0612, -0.2235,\n",
       "                       0.1478, -0.0808, -0.1013, -0.1293])),\n",
       "             ('predict.weight',\n",
       "              tensor([[ 0.0202,  0.0195,  0.0593, -0.0512,  0.0080,  0.0694, -0.0648,  0.0830,\n",
       "                       -0.0351,  0.0024,  0.0304, -0.0169,  0.0459, -0.0544, -0.0663, -0.0035,\n",
       "                        0.0018,  0.0521, -0.0406,  0.0101, -0.0089, -0.0896, -0.0300,  0.0237,\n",
       "                        0.0020, -0.0037,  0.0909,  0.0052, -0.0413,  0.0365,  0.0716, -0.0380,\n",
       "                        0.0591, -0.0601, -0.0653,  0.0165, -0.0332,  0.0221, -0.0889, -0.0046,\n",
       "                        0.0244,  0.0361, -0.0225, -0.0646,  0.0745, -0.1306, -0.0070,  0.0805,\n",
       "                       -0.0606,  0.0185, -0.0006, -0.0133, -0.0022, -0.0393,  0.0537,  0.0301,\n",
       "                       -0.0269,  0.0807,  0.0863,  0.0128,  0.0798, -0.0792,  0.0645, -0.0553,\n",
       "                       -0.0119, -0.0906,  0.0515, -0.0162,  0.0159, -0.0180,  0.0202,  0.0255,\n",
       "                       -0.0236, -0.0148,  0.0289, -0.0838, -0.0407, -0.0428,  0.0255, -0.0851,\n",
       "                        0.0333,  0.0645,  0.0883,  0.0495, -0.0864, -0.0020, -0.0418, -0.0016,\n",
       "                        0.0882,  0.0819,  0.0067, -0.0241,  0.0650,  0.0581, -0.0382, -0.0002,\n",
       "                        0.0239,  0.0032,  0.0607,  0.0523]])),\n",
       "             ('predict.bias', tensor([0.0085]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.load_state_dict(torch.load(path))\n",
    "net2.eval()\n",
    "net2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[-0.0676, -0.0373, -0.0625,  ..., -0.0039, -0.2168,  0.0727],\n",
       "                      [-0.1252, -0.0744, -0.0562,  ..., -0.1339, -0.1475,  0.1869],\n",
       "                      [ 0.1879, -0.0744, -0.0616,  ..., -0.1756,  0.0499, -0.2314],\n",
       "                      ...,\n",
       "                      [-0.1955,  0.1512, -0.1365,  ...,  0.0670, -0.1679,  0.0434],\n",
       "                      [ 0.1207,  0.0385,  0.1566,  ...,  0.0703,  0.0622,  0.0010],\n",
       "                      [ 0.1169,  0.1795, -0.0860,  ..., -0.1801, -0.1532, -0.1962]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([-0.0537,  0.1449, -0.1245,  0.0153,  0.0911, -0.1218, -0.0173,  0.0280,\n",
       "                       0.0580, -0.3124, -0.1526, -0.1387,  0.1176,  0.0327, -0.1876,  0.1053,\n",
       "                      -0.1954,  0.1189,  0.2141, -0.1075, -0.2272, -0.0854, -0.2294,  0.0227,\n",
       "                       0.0784,  0.0967,  0.0996, -0.0641, -0.1181,  0.0893,  0.1770, -0.0827,\n",
       "                      -0.2538, -0.1078,  0.0648, -0.0968, -0.1060, -0.1650, -0.0345, -0.0484,\n",
       "                       0.0710,  0.0583, -0.0253, -0.1054, -0.1782, -0.0317,  0.0053, -0.1927,\n",
       "                       0.1073, -0.1297, -0.1999,  0.1369,  0.1121, -0.2453,  0.1417,  0.0692,\n",
       "                       0.0474,  0.1481, -0.0113,  0.1698,  0.0015, -0.1651, -0.1385, -0.0097,\n",
       "                      -0.1946,  0.0901, -0.1554, -0.2093,  0.1432,  0.0078,  0.0937, -0.0760,\n",
       "                      -0.2003,  0.1421,  0.2173,  0.0411,  0.0294, -0.1756, -0.0482, -0.2211,\n",
       "                       0.1413,  0.1816, -0.1979, -0.1173,  0.1409, -0.1318, -0.0694, -0.0843,\n",
       "                      -0.1675,  0.1520,  0.1975, -0.1841,  0.0926,  0.0575,  0.0612, -0.2235,\n",
       "                       0.1478, -0.0808, -0.1013, -0.1293])),\n",
       "             ('predict.weight',\n",
       "              tensor([[ 0.0202,  0.0195,  0.0593, -0.0512,  0.0080,  0.0694, -0.0648,  0.0830,\n",
       "                       -0.0351,  0.0024,  0.0304, -0.0169,  0.0459, -0.0544, -0.0663, -0.0035,\n",
       "                        0.0018,  0.0521, -0.0406,  0.0101, -0.0089, -0.0896, -0.0300,  0.0237,\n",
       "                        0.0020, -0.0037,  0.0909,  0.0052, -0.0413,  0.0365,  0.0716, -0.0380,\n",
       "                        0.0591, -0.0601, -0.0653,  0.0165, -0.0332,  0.0221, -0.0889, -0.0046,\n",
       "                        0.0244,  0.0361, -0.0225, -0.0646,  0.0745, -0.1306, -0.0070,  0.0805,\n",
       "                       -0.0606,  0.0185, -0.0006, -0.0133, -0.0022, -0.0393,  0.0537,  0.0301,\n",
       "                       -0.0269,  0.0807,  0.0863,  0.0128,  0.0798, -0.0792,  0.0645, -0.0553,\n",
       "                       -0.0119, -0.0906,  0.0515, -0.0162,  0.0159, -0.0180,  0.0202,  0.0255,\n",
       "                       -0.0236, -0.0148,  0.0289, -0.0838, -0.0407, -0.0428,  0.0255, -0.0851,\n",
       "                        0.0333,  0.0645,  0.0883,  0.0495, -0.0864, -0.0020, -0.0418, -0.0016,\n",
       "                        0.0882,  0.0819,  0.0067, -0.0241,  0.0650,  0.0581, -0.0382, -0.0002,\n",
       "                        0.0239,  0.0032,  0.0607,  0.0523]])),\n",
       "             ('predict.bias', tensor([0.0085]))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_returned.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [60367 x 22], m2: [21 x 100] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:136",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d454bc387c0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# y_pred = net(X) #This outputs the value for regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnet_returned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/GEOANN/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1c6dbaa18d52>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# activation function for hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;31m# linear output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/GEOANN/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/GEOANN/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/GEOANN/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [60367 x 22], m2: [21 x 100] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:136"
     ]
    }
   ],
   "source": [
    "#Get X data ready\n",
    "X_pred=prediction_set_aggregated_dt.values\n",
    "X = Variable(torch.FloatTensor(X_pred)) \n",
    "X\n",
    "#Make predictions\n",
    "# y_pred = net(X) #This outputs the value for regression\n",
    "net_returned(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Initialize the maturity prediction model:\n",
    "        model = MaturityPrediction()\n",
    "        \n",
    "        for model_code, model_field in field_codes.items():\n",
    "            # Define the location of the saved weigths:\n",
    "            model_file_name = f'../data/{model_code}_{fold}_rnd_1_noaug.pth'\n",
    "\n",
    "            # Load model parameters:\n",
    "            model.load_state_dict(torch.load(model_file_name))\n",
    "\n",
    "            # Load the model into the GPU:\n",
    "            model = model.to(device)\n",
    "            model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = prediction_set_aggregated_df[['rain_30', 'rain_60','rain_90', 't_max_30', 't_max_60', 't_max_90', 't_min_30', 't_min_60', 't_min_90', 'Y_prev',\n",
    " 'Y_corn_lt_avg', 'day_sow', 'day_v5', 'lai_v5', 'whc', 'oc_20cm_v5', 'sw_dep_v5', 'n_0_60cm_v5', 'surfaceom_wt_v5', 'sand_40cm', 'clay_40cm']]\n",
    "X_pred=X_pred.values\n",
    "\n",
    "X = Variable(torch.FloatTensor(X_pred)) \n",
    "y_pred = net(X) #This outputs the value for regression\n",
    "y_pred=y_pred.data[:,0].numpy()\n",
    "\n",
    "prediction_set_aggregated_df['eonr_pred'] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "X = Variable(torch.FloatTensor(X_train)) \n",
    "result = net(X)\n",
    "# pred=result.data[:,0].numpy()\n",
    "# print(len(pred),len(y_train))\n",
    "# r2_score(pred,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = prediction_set_aggregated_df[['rain_30', 'rain_60','rain_90', 't_max_30', 't_max_60', 't_max_90', 't_min_30', 't_min_60', 't_min_90', 'Y_prev',\n",
    " 'Y_corn_lt_avg', 'day_sow', 'day_v5', 'lai_v5', 'whc', 'oc_20cm_v5', 'sw_dep_v5', 'n_0_60cm_v5', 'surfaceom_wt_v5', 'sand_40cm', 'clay_40cm']]\n",
    "X_pred=X_pred.values\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE PREDICTIONS\n",
    "X = Variable(torch.FloatTensor(X_pred)) \n",
    "y_pred = net(X) #This outputs the value for regression\n",
    "y_pred=y_pred.data[:,0].numpy()\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_set_aggregated_df['eonr_pred'] = y_pred\n",
    "prediction_set_aggregated_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's write a Rds\n",
    "pyreadr.write_rds(\"/home/germanm2/n_policy_box/Data/files_rds/prediction_set_aggregated_cnn_df.rds\", prediction_set_aggregated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GEOANN]",
   "language": "python",
   "name": "conda-env-GEOANN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
